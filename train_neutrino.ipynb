{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import models, Model\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "from sparsepixels.layers import *\n",
    "from sparsepixels.utils import *\n",
    "\n",
    "#### ---> extract raw images and necessary info from official samples\n",
    "#run_batch(which=\"inclusive\", overwrite_outputs=True, store_all=True)\n",
    "#run_batch(which=\"nue\", overwrite_outputs=True, store_all=True)\n",
    "\n",
    "#### ---> slim files with filtering by min signal hits\n",
    "#incl_in = [f\"datasets/neutrino/data_inclusive_plane{p}.h5\" for p in (0,1,2)]\n",
    "#incl_out = [f\"datasets/neutrino/data_inclusive_plane{p}_slim_500.h5\" for p in (0,1,2)]\n",
    "#nue_in = [f\"datasets/neutrino/data_nue_plane{p}.h5\" for p in (0,1,2)]\n",
    "#nue_out = [f\"datasets/neutrino/data_nue_plane{p}_slim_500.h5\" for p in (0,1,2)]\n",
    "#for inp, outp in zip(incl_in, incl_out):\n",
    "    #write_slim_plane_ge_threshold(inp, outp, threshold=500, overwrite=True, verbose=True)\n",
    "#for inp, outp in zip(nue_in, nue_out):\n",
    "    #write_slim_plane_ge_threshold(inp, outp, threshold=500, overwrite=True, verbose=True)\n",
    "\n",
    "#### ---> extract sig/bkg windows into training-ready files\n",
    "#write_patches_from_slim_file(\"datasets/neutrino/data_inclusive_plane2_slim_500.h5\", win_t=256, win_w=512, num_bkg=5)\n",
    "#write_patches_from_slim_file(\"datasets/neutrino/data_inclusive_plane0_slim_500.h5\", win_t=256, win_w=512, num_bkg=5)\n",
    "#write_patches_from_slim_file(\"datasets/neutrino/data_inclusive_plane1_slim_500.h5\", win_t=256, win_w=512, num_bkg=5)\n",
    "#write_patches_from_slim_file(\"datasets/neutrino/data_nue_plane0_slim_500.h5\", win_t=256, win_w=512, num_bkg=5)\n",
    "#write_patches_from_slim_file(\"datasets/neutrino/data_nue_plane1_slim_500.h5\", win_t=256, win_w=512, num_bkg=5)\n",
    "#write_patches_from_slim_file(\"datasets/neutrino/data_nue_plane2_slim_500.h5\", win_t=256, win_w=512, num_bkg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_plane_sample(\"datasets/neutrino/data_inclusive_plane2_slim_500.h5\", idx=0, p='raw',   jet_vmin=0, jet_vmax=100, cmap='gist_ncar')\n",
    "#plot_plane_sample(\"datasets/neutrino/data_inclusive_plane2_slim_500.h5\", idx=0, p='sig', point_size=3)\n",
    "#plot_plane_sample(\"datasets/neutrino/data_inclusive_plane2_slim_500.h5\", idx=0, p='bkg', point_size=3)\n",
    "#plot_plane_sample(\"datasets/neutrino/data_inclusive_plane2_slim_500.h5\", idx=0, p='sigbkg', point_size=3)\n",
    "\n",
    "run_window_demo(\"datasets/neutrino/data_inclusive_plane2_slim_500.h5\", first_N=5, win_t=256, win_w=512, num_bkg=5, cmap='gist_ncar', vmin=0, vmax=100)\n",
    "#run_window_demo(\"datasets/neutrino/data_nue_plane2_slim_500.h5\", first_N=5, win_t=256, win_w=512, num_bkg=5, cmap='gist_ncar', vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_patches(\"datasets/neutrino/data_inclusive_plane2_slim_500_patches_sig_t256w512.h5\", max_examples=5, start_idx=0, cmap='gist_ncar', vmin=0, vmax=100)\n",
    "preview_patches(\"datasets/neutrino/data_inclusive_plane2_slim_500_patches_bkg_t256w512.h5\", max_examples=5, start_idx=0, cmap='gist_ncar', vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr=700; pool_t=4; pool_w=8; vmax_pool=pool_t*pool_w*100*0.7\n",
    "preview_patches_with_pooling(\"datasets/neutrino/data_inclusive_plane2_slim_500_patches_sig_t256w512.h5\",\n",
    "    max_examples=5, start_idx=0, pool_t=pool_t, pool_w=pool_w, thr=thr,\n",
    "    vmin_raw=0,vmax_raw=100,  vmin_pool=0,vmax_pool=vmax_pool,  vmin_thr=0,vmax_thr=vmax_pool)\n",
    "preview_patches_with_pooling(\"datasets/neutrino/data_inclusive_plane2_slim_500_patches_bkg_t256w512.h5\",\n",
    "    max_examples=5, start_idx=0, pool_t=pool_t, pool_w=pool_w, thr=thr,\n",
    "    vmin_raw=0,vmax_raw=100,  vmin_pool=0,vmax_pool=vmax_pool,  vmin_thr=0,vmax_thr=vmax_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ca022",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_files = [\"datasets/neutrino/data_inclusive_plane2_slim_500_patches_sig_t256w512.h5\",\n",
    "             \"datasets/neutrino/data_inclusive_plane1_slim_500_patches_sig_t256w512.h5\",\n",
    "             \"datasets/neutrino/data_inclusive_plane0_slim_500_patches_sig_t256w512.h5\",\n",
    "             \"datasets/neutrino/data_nue_plane2_slim_500_patches_sig_t256w512.h5\",\n",
    "             \"datasets/neutrino/data_nue_plane1_slim_500_patches_sig_t256w512.h5\",\n",
    "             \"datasets/neutrino/data_nue_plane0_slim_500_patches_sig_t256w512.h5\",\n",
    "]\n",
    "bkg_files = [\"datasets/neutrino/data_inclusive_plane2_slim_500_patches_bkg_t256w512.h5\",\n",
    "             #\"datasets/neutrino/data_inclusive_plane1_slim_500_patches_bkg_t256w512.h5\",\n",
    "             #\"datasets/neutrino/data_inclusive_plane0_slim_500_patches_bkg_t256w512.h5\",\n",
    "             \"datasets/neutrino/data_nue_plane2_slim_500_patches_bkg_t256w512.h5\",\n",
    "             #\"datasets/neutrino/data_nue_plane1_slim_500_patches_bkg_t256w512.h5\",\n",
    "             #\"datasets/neutrino/data_nue_plane0_slim_500_patches_bkg_t256w512.h5\",\n",
    "]\n",
    "\n",
    "X_list, y_list = [], []\n",
    "sig_list, bkg_list = [], []\n",
    "\n",
    "for file_group, label in [(sig_files, 1), (bkg_files, 0)]:\n",
    "    for path in file_group:\n",
    "        with h5py.File(path, \"r\") as g:\n",
    "            imgs = g[\"image\"][:]\n",
    "            sigm = g[\"sigmask\"][:]\n",
    "            bkgm = g[\"bkgmask\"][:]\n",
    "\n",
    "            T, W = imgs.shape[1], imgs.shape[2]\n",
    "            target_shape = (T, W)\n",
    "\n",
    "            imgs = imgs[..., np.newaxis].astype(np.float32)\n",
    "            sigm = sigm[..., np.newaxis].astype(np.uint8)\n",
    "            bkgm = bkgm[..., np.newaxis].astype(np.uint8)\n",
    "\n",
    "            X_list.append(imgs)\n",
    "            y_list.append(np.full((imgs.shape[0], 1), label, dtype=np.int64))\n",
    "            sig_list.append(sigm)\n",
    "            bkg_list.append(bkgm)\n",
    "\n",
    "            print(f\"{imgs.shape[0]} patches from {path} (label={label})\")\n",
    "\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "mask_sig = np.concatenate(sig_list, axis=0)\n",
    "mask_bkg = np.concatenate(bkg_list, axis=0)\n",
    "\n",
    "print(\"\\nshapes:\")\n",
    "print(\"X       :\", X.shape)\n",
    "print(\"y       :\", y.shape, \", counts:\", np.unique(y, return_counts=True))\n",
    "print(\"mask_sig:\", mask_sig.shape)\n",
    "print(\"mask_bkg:\", mask_bkg.shape)\n",
    "\n",
    "# data pooling\n",
    "pool_t = 4\n",
    "pool_w = 8\n",
    "thr = 700\n",
    "batch = 512\n",
    "\n",
    "N, T, W, C = X.shape\n",
    "new_T = T // pool_t\n",
    "new_W = W // pool_w\n",
    "\n",
    "X_out = np.empty((N, new_T, new_W, C), dtype=X.dtype)\n",
    "mask_sig_out = np.empty((N, new_T, new_W, C), dtype=np.uint8)\n",
    "mask_bkg_out = np.empty((N, new_T, new_W, C), dtype=np.uint8)\n",
    "\n",
    "for i0 in range(0, N, batch):\n",
    "    i1 = min(i0 + batch, N)\n",
    "    x = X[i0:i1]\n",
    "    ms = mask_sig[i0:i1]\n",
    "    mb = mask_bkg[i0:i1]\n",
    "\n",
    "    x_pool  = x.reshape(-1, new_T, pool_t, new_W, pool_w, 1).sum(axis=(2,4))\n",
    "    ms_pool = ms.reshape(-1, new_T, pool_t, new_W, pool_w, 1).max(axis=(2,4))\n",
    "    mb_pool = mb.reshape(-1, new_T, pool_t, new_W, pool_w, 1).max(axis=(2,4))\n",
    "\n",
    "    if thr is not None:\n",
    "        x_pool[x_pool < thr] = 0\n",
    "\n",
    "    X_out[i0:i1] = x_pool\n",
    "    mask_sig_out[i0:i1] = ms_pool\n",
    "    mask_bkg_out[i0:i1] = mb_pool\n",
    "\n",
    "X, mask_sig, mask_bkg = X_out, mask_sig_out, mask_bkg_out\n",
    "del X_out, mask_sig_out, mask_bkg_out\n",
    "\n",
    "print(\"\\nafter:\")\n",
    "print(\"X       :\", X.shape)\n",
    "print(\"mask_sig:\", mask_sig.shape)\n",
    "print(\"mask_bkg:\", mask_bkg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sig = 4\n",
    "n_bkg = 4\n",
    "start_sig = 0\n",
    "start_bkg = 0\n",
    "\n",
    "yy = y.squeeze()\n",
    "sig_idx = np.where(yy==1)[0][start_sig:start_sig+n_sig]\n",
    "bkg_idx = np.where(yy==0)[0][start_bkg:start_bkg+n_bkg]\n",
    "\n",
    "def quick_plot(idx, cls):\n",
    "    img = X[idx, :, :, 0]\n",
    "    nhits = int((img>0).sum())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(img, origin='lower', aspect='auto', cmap='gist_ncar', vmin=0, vmax=2000)\n",
    "    cb = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.02)\n",
    "    #cb.set_label(\"ADC\")\n",
    "    ax.set_title(f\"{cls}, #hits={nhits}\")\n",
    "    ax.set_xlabel(\"wire\")\n",
    "    ax.set_ylabel(\"time\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for i in sig_idx:\n",
    "    quick_plot(int(i), \"sig\")\n",
    "for i in bkg_idx:\n",
    "    quick_plot(int(i), \"bkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# balance sig/bkg\n",
    "yy = y.squeeze()\n",
    "sig_idx = np.where(yy == 1)[0]\n",
    "bkg_idx = np.where(yy == 0)[0]\n",
    "\n",
    "n_per_cls = min(sig_idx.size, bkg_idx.size)\n",
    "sig_sel = rng.choice(sig_idx, size=n_per_cls, replace=False)\n",
    "bkg_sel = rng.choice(bkg_idx, size=n_per_cls, replace=False)\n",
    "\n",
    "idx_bal = np.concatenate([sig_sel, bkg_sel])\n",
    "\n",
    "X = X[idx_bal]\n",
    "y = y[idx_bal]\n",
    "mask_sig = mask_sig[idx_bal]\n",
    "mask_bkg = mask_bkg[idx_bal]\n",
    "\n",
    "# shuffle\n",
    "perm = rng.permutation(X.shape[0])\n",
    "X, y, mask_sig, mask_bkg = X[perm], y[perm], mask_sig[perm], mask_bkg[perm]\n",
    "\n",
    "X = X[:, :63, :63, :]\n",
    "\n",
    "# split\n",
    "n_train = int(X.shape[0] * 0.7)\n",
    "n_val = int(X.shape[0] * 0.1)\n",
    "n_test = X.shape[0] - n_train - n_val\n",
    "\n",
    "x_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "x_val = X[n_train:n_train+n_val]\n",
    "y_val = y[n_train:n_train+n_val]\n",
    "x_test = X[n_train+n_val:n_train+n_val+n_test]\n",
    "y_test = y[n_train+n_val:n_train+n_val+n_test]\n",
    "\n",
    "mask_sig_train = mask_sig[:n_train]\n",
    "mask_bkg_train = mask_bkg[:n_train]\n",
    "mask_sig_val = mask_sig[n_train:n_train+n_val]\n",
    "mask_bkg_val = mask_bkg[n_train:n_train+n_val]\n",
    "mask_sig_test = mask_sig[n_train+n_val:n_train+n_val+n_test]\n",
    "mask_bkg_test = mask_bkg[n_train+n_val:n_train+n_val+n_test]\n",
    "\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"x_val.shape:  \", x_val.shape)\n",
    "print(\"y_val.shape:  \", y_val.shape)\n",
    "print(\"x_test.shape: \", x_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)\n",
    "\n",
    "def counts_str(yarr):\n",
    "    lab, cnt = np.unique(yarr.squeeze(), return_counts=True)\n",
    "    return dict(zip(lab.tolist(), cnt.tolist()))\n",
    "\n",
    "print(\"\\nclass counts:\")\n",
    "print(\"train:\", counts_str(y_train))\n",
    "print(\"val  :\", counts_str(y_val))\n",
    "print(\"test :\", counts_str(y_test))\n",
    "\n",
    "x_train = (x_train / (pool_t*pool_w*100)).astype(np.float32)\n",
    "x_val = (x_val / (pool_t*pool_w*100)).astype(np.float32)\n",
    "x_test = (x_test / (pool_t*pool_w*100)).astype(np.float32)\n",
    "\n",
    "del X, y, mask_sig, mask_bkg\n",
    "\n",
    "import os\n",
    "import random\n",
    "os.environ['PYTHONHASHSEED'] = str(1219)\n",
    "random.seed(1219)\n",
    "tf.random.set_seed(1219)\n",
    "np.random.seed(1219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(is_sparse, n_max_pixels=None):\n",
    "    #quantizer = quantized_bits(8, 0, alpha=1)\n",
    "    #quantized_relu = 'quantized_relu(8, 0)'\n",
    "\n",
    "    quantizer = quantized_bits(16, 6, alpha=1)\n",
    "    quantized_relu = 'quantized_relu(16, 6)'\n",
    "\n",
    "    x_in = keras.Input(shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3]), name='x_in')\n",
    "    if is_sparse:\n",
    "        x, keep_mask = InputReduce(n_max_pixels=n_max_pixels, threshold=0, name='input_reduce')(x_in)\n",
    "    else:\n",
    "        x = x_in\n",
    "\n",
    "    if is_sparse:\n",
    "        x = QConv2DSparse(filters=1, kernel_size=7, use_bias=True, name='conv1', padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "\n",
    "        x = QConv2DSparse(filters=3, kernel_size=7, use_bias=True, name='conv2', padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "        x, keep_mask = AveragePooling2DSparse(7, name='pool1')([x, keep_mask])\n",
    "\n",
    "    else:\n",
    "        x = QConv2D(filters=1, kernel_size=7, use_bias=True, name='conv1', padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "        #x = AveragePooling2D(2, name='pool1')(x)\n",
    "\n",
    "        x = QConv2D(filters=3, kernel_size=7, use_bias=True, name='conv2', padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "        x = AveragePooling2D(7, name='pool1')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    x = QDense(16, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense1')(x)\n",
    "    x = QActivation(quantized_relu, name='relu3')(x)\n",
    "\n",
    "    x = QDense(1, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense2')(x)\n",
    "    x = Activation('sigmoid', name='sigmoid')(x)\n",
    "\n",
    "    name = 'cnn_sparse'\n",
    "    if not is_sparse:\n",
    "        name = 'cnn_full'\n",
    "    return keras.Model(x_in, x, name=name)\n",
    "\n",
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_full.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(cnn_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e66912",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-3,\n",
    "    patience=15,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "cnn_sparse_t = build_cnn(is_sparse=True, n_max_pixels=8)\n",
    "cnn_sparse_t.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_t.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "#history = cnn_sparse_t.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=16, batch_size=128)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd14820",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_s = build_cnn(is_sparse=True, n_max_pixels=12)\n",
    "cnn_sparse_s.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_s.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "#history = cnn_sparse_s.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=16, batch_size=128)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793303ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_m = build_cnn(is_sparse=True, n_max_pixels=16)\n",
    "cnn_sparse_m.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_m.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "#history = cnn_sparse_m.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=16, batch_size=128)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb667c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_l = build_cnn(is_sparse=True, n_max_pixels=20)\n",
    "cnn_sparse_l.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_l.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "#history = cnn_sparse_l.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=18, batch_size=128)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_full.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_full.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "#history = cnn_full.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=16, batch_size=128)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bebedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sparse_t = cnn_sparse_t.predict(x_test)\n",
    "y_pred_sparse_s = cnn_sparse_s.predict(x_test)\n",
    "y_pred_sparse_m = cnn_sparse_m.predict(x_test)\n",
    "y_pred_sparse_l = cnn_sparse_l.predict(x_test)\n",
    "y_pred_full = cnn_full.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215497ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_true, y_preds, labels):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for y_pred, name in zip(y_preds, labels):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        a = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1.5, label=f\"{name} (auc={a:.3f})\")\n",
    "\n",
    "    #plt.xscale('log')\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(y_true=y_test,  \n",
    "         y_preds=[y_pred_sparse_t, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full],\n",
    "         labels=[\"sparse-t\", \"sparse-s\", \"sparse-m\", \"sparse-l\", \"standard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [\n",
    "    'x_in', 'input_reduce',\n",
    "    'conv1', 'relu1', #'pool1',\n",
    "    'conv2', 'relu2', 'pool1',\n",
    "]\n",
    "\n",
    "plot_tensors = []\n",
    "plot_names = []\n",
    "for name in layer_names:\n",
    "    layer = cnn_sparse_l.get_layer(name)\n",
    "    output = layer.output\n",
    "    if isinstance(output, (list, tuple)):\n",
    "        plot_tensors.append(output[0])\n",
    "        plot_names.append(f'{name} (x_reduced)')\n",
    "        plot_tensors.append(output[1])\n",
    "        plot_names.append(f'{name} (x_mask)')\n",
    "    else:\n",
    "        plot_tensors.append(output)\n",
    "        plot_names.append(name)\n",
    "\n",
    "model_cnnpart = models.Model(inputs=cnn_sparse_l.input, outputs=plot_tensors)\n",
    "layers_pred = model_cnnpart.predict(x_test[31:32])\n",
    "\n",
    "i = 0\n",
    "while i < len(plot_names):\n",
    "    name = plot_names[i]\n",
    "\n",
    "    if \"(x_reduced)\" in name and i+1 < len(plot_names) and \"(x_mask)\" in plot_names[i+1]:\n",
    "        out_r = layers_pred[i] # (1, h, w, c)\n",
    "        out_m = layers_pred[i+1] # (1, h, w, 1)\n",
    "\n",
    "        arr_r = out_r[0] # (h, w, c)\n",
    "        arr_m = out_m[0,...,0] # (h, w)\n",
    "        h, w, c = arr_r.shape\n",
    "\n",
    "        fig, axes = plt.subplots(1, c+1, figsize=((c+1)*3, 3))\n",
    "        fig.suptitle(name.replace(\" (x_reduced)\", \"\"), fontsize=14)\n",
    "\n",
    "        for ch in range(c):\n",
    "            ax = axes[ch]\n",
    "            ax.imshow(arr_r[..., ch], cmap='gray')\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "\n",
    "        axm = axes[c]\n",
    "        axm.imshow(arr_m, cmap='gray')\n",
    "        axm.set_title(\"mask\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        i += 2\n",
    "        continue\n",
    "\n",
    "    out = layers_pred[i]\n",
    "    arr = out[0]\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "        fig.suptitle(name, fontsize=14)\n",
    "        ax.imshow(arr, cmap='gray')\n",
    "        ax.set_title(\"ch0\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    elif arr.ndim == 3:\n",
    "        h, w, c = arr.shape\n",
    "        fig, axes = plt.subplots(1, c, figsize=(c*3, 3))\n",
    "        fig.suptitle(name, fontsize=14)\n",
    "        for ch in range(c):\n",
    "            ax = axes[ch] if c>1 else axes\n",
    "            ax.imshow(arr[..., ch], cmap='gray')\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full.save_weights('weights/neutrino_full-16b.h5')\n",
    "cnn_sparse_t.save_weights('weights/neutrino_sparse_t-16b.h5')\n",
    "cnn_sparse_s.save_weights('weights/neutrino_sparse_s-16b.h5')\n",
    "cnn_sparse_m.save_weights('weights/neutrino_sparse_m-16b.h5')\n",
    "cnn_sparse_l.save_weights('weights/neutrino_sparse_l-16b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_sparse_t = build_cnn(is_sparse=True, n_max_pixels=8)\n",
    "cnn_sparse_s = build_cnn(is_sparse=True, n_max_pixels=12)\n",
    "cnn_sparse_m = build_cnn(is_sparse=True, n_max_pixels=16)\n",
    "cnn_sparse_l = build_cnn(is_sparse=True, n_max_pixels=20)\n",
    "\n",
    "cnn_full.load_weights('weights/neutrino_full-16b.h5')\n",
    "cnn_sparse_t.load_weights('weights/neutrino_sparse_t-16b.h5')\n",
    "cnn_sparse_s.load_weights('weights/neutrino_sparse_s-16b.h5')\n",
    "cnn_sparse_m.load_weights('weights/neutrino_sparse_m-16b.h5')\n",
    "cnn_sparse_l.load_weights('weights/neutrino_sparse_l-16b.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0f876",
   "metadata": {},
   "source": [
    "## hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_sparse_forhls(cnn_sparse):\n",
    "    x_in = keras.Input(shape=cnn_sparse.input_shape[1:], name=\"x_in\")\n",
    "    x = x_in\n",
    "    for layer in cnn_sparse.layers:\n",
    "        if isinstance(layer, keras.layers.InputLayer):\n",
    "            continue\n",
    "        if isinstance(layer, InputReduce):\n",
    "            continue\n",
    "        if layer.name.startswith(\"mask_pool\"):\n",
    "            continue\n",
    "\n",
    "        if isinstance(layer, QConv2DSparse):\n",
    "            cfg = layer.conv.get_config()\n",
    "            cfg[\"use_bias\"] = True\n",
    "            cfg[\"name\"] = layer.name\n",
    "            cfg[\"bias_quantizer\"] = layer._bias_quant_cfg\n",
    "\n",
    "            conv_full = QConv2D.from_config(cfg)\n",
    "            x = conv_full(x)\n",
    "\n",
    "            kernel_w = layer.conv.get_weights()[0]\n",
    "            bias_w = keras.backend.get_value(layer.bias)\n",
    "            conv_full.set_weights([kernel_w, bias_w])\n",
    "        elif isinstance(layer, AveragePooling2DSparse):\n",
    "            x = layer.avg_pool(x)\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return keras.Model(x_in, x, name='cnn_sparse_forhls')\n",
    "\n",
    "cnn_sparse_t_forhls = build_cnn_sparse_forhls(cnn_sparse_t)\n",
    "cnn_sparse_s_forhls = build_cnn_sparse_forhls(cnn_sparse_s)\n",
    "cnn_sparse_m_forhls = build_cnn_sparse_forhls(cnn_sparse_m)\n",
    "cnn_sparse_l_forhls = build_cnn_sparse_forhls(cnn_sparse_l)\n",
    "cnn_sparse_s_forhls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f13e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "def write_sparse_hls(cnn_sparse_forhls, name):\n",
    "    config = hls4ml.utils.config_from_keras_model(cnn_sparse_forhls, granularity='name', backend='Vitis')\n",
    "    #config['LayerName']['x_in']['Precision'] = 'ap_ufixed<8,1>'\n",
    "    #config\n",
    "\n",
    "    cnn_sparse_hls = hls4ml.converters.convert_from_keras_model(\n",
    "        cnn_sparse_forhls,\n",
    "        hls_config=config,\n",
    "        project_name='myhls',\n",
    "        backend='Vitis',\n",
    "        output_dir=f'hls_proj/neutrino/model-16b/{name}',\n",
    "        part='xcu250-figd2104-2L-e',\n",
    "        io_type='io_parallel',\n",
    "    )\n",
    "\n",
    "    #cnn_sparse_hls.compile()\n",
    "    cnn_sparse_hls.write()\n",
    "\n",
    "write_sparse_hls(cnn_sparse_t_forhls, 'hls_sparse_t')\n",
    "write_sparse_hls(cnn_sparse_s_forhls, 'hls_sparse_s')\n",
    "write_sparse_hls(cnn_sparse_m_forhls, 'hls_sparse_m')\n",
    "write_sparse_hls(cnn_sparse_l_forhls, 'hls_sparse_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(cnn_full, granularity='name', backend='Vivado')\n",
    "#config['LayerName']['x_in']['Precision'] = 'ap_ufixed<8,1>'\n",
    "#config['LayerName']['conv1']['ParallelizationFactor'] = 200\n",
    "#config['LayerName']['conv2']['ParallelizationFactor'] = 50\n",
    "#config\n",
    "\n",
    "cnn_full_hls = hls4ml.converters.convert_from_keras_model(\n",
    "    cnn_full,\n",
    "    hls_config=config,\n",
    "    project_name='myhls',\n",
    "    backend='Vivado',\n",
    "    output_dir='hls_proj/neutrino/model-16b/hls_full',\n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    io_type='io_stream',\n",
    ")\n",
    "\n",
    "#cnn_full_hls.compile()\n",
    "cnn_full_hls.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80648905",
   "metadata": {},
   "source": [
    "## testbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tb = 100\n",
    "x_tb = x_test[:n_tb]\n",
    "y_tb_t = y_pred_sparse_t[:n_tb]\n",
    "y_tb_s = y_pred_sparse_s[:n_tb]\n",
    "y_tb_m = y_pred_sparse_m[:n_tb]\n",
    "y_tb_l = y_pred_sparse_l[:n_tb]\n",
    "y_tb_full = y_pred_full[:n_tb]\n",
    "\n",
    "bit = \"16b\"\n",
    "\n",
    "# inputs\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_t/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_s/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_m/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_l/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_full/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# predictions\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_t/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_t:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_s/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_s:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_m/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_m:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_sparse_l/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_l:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/neutrino/model-\"+bit+\"/hls_full/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_full:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044733f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
