{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import models, Model\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "from sparsepixels.layers import *\n",
    "from sparsepixels.utils import *\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "n_val = 10000\n",
    "X_val = X_train[:n_val]\n",
    "y_val = y_train[:n_val]\n",
    "X_train = X_train[n_val:]\n",
    "y_train = y_train[n_val:]\n",
    "\n",
    "X_train = np.reshape(X_train, (-1,28,28,1)) / 255.\n",
    "X_val = np.reshape(X_val, (-1,28,28,1)) / 255.\n",
    "X_test = np.reshape(X_test, (-1,28,28,1)) / 255.\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"y_train.shape: \" + str(y_train.shape))\n",
    "print(\"X_val.shape: \" + str(X_val.shape))\n",
    "print(\"y_val.shape: \" + str(y_val.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"y_test.shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c655197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "os.environ['PYTHONHASHSEED'] = str(1221)\n",
    "random.seed(1221)\n",
    "tf.random.set_seed(1221)\n",
    "np.random.seed(1211)\n",
    "\n",
    "noise_type='uniform'\n",
    "#noise_type='poisson'\n",
    "#noise_level=0.42\n",
    "noise_level=0\n",
    "inflate_factor=3.5\n",
    "threshold=0.4\n",
    "target_size_x=48\n",
    "target_size_y=target_size_x\n",
    "\n",
    "x_train_pooled = pool_pad_noise_inflate(X_train, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=0, inflate_factor=1)\n",
    "x_train_pooled_inflated = pool_pad_noise_inflate(X_train, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=0, inflate_factor=inflate_factor)\n",
    "\n",
    "x_train = pool_pad_noise_inflate(X_train, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=noise_level, inflate_factor=inflate_factor)\n",
    "x_val = pool_pad_noise_inflate(X_val, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=noise_level, inflate_factor=inflate_factor)\n",
    "x_test = pool_pad_noise_inflate(X_test, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=noise_level, inflate_factor=inflate_factor)\n",
    "\n",
    "x_train[x_train < threshold] = 0.\n",
    "x_val[x_val < threshold] = 0.\n",
    "x_test[x_test < threshold] = 0.\n",
    "\n",
    "for i in range(5):\n",
    "    plot_sparsemnist(X_train, x_train_pooled, x_train_pooled_inflated, x_train, i, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(is_sparse, B=16, I=6, n_max_pixels=None):\n",
    "    #quantizer = quantized_bits(16, 6, alpha=1)\n",
    "    #quantized_relu = 'quantized_relu(16, 6)'\n",
    "\n",
    "    quantizer = quantized_bits(B, I, alpha=1)\n",
    "    quantized_relu = f'quantized_relu({B}, {I})'\n",
    "\n",
    "    x_in = keras.Input(shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3]), name='x_in')\n",
    "    if is_sparse:\n",
    "        x, keep_mask = InputReduce(n_max_pixels=n_max_pixels, threshold=threshold, name='input_reduce')(x_in)\n",
    "    else:\n",
    "        x = x_in\n",
    "\n",
    "    if is_sparse:\n",
    "        x = QConv2DSparse(filters=1, kernel_size=7, use_bias=True, name='conv1', padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "        x, keep_mask = AveragePooling2DSparse(4, name='pool1')([x, keep_mask])\n",
    "\n",
    "        x = QConv2DSparse(filters=3, kernel_size=5, use_bias=True, name='conv2', padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "        x, keep_mask = AveragePooling2DSparse(2, name='pool2')([x, keep_mask])\n",
    "\n",
    "    else:\n",
    "        x = QConv2D(filters=1, kernel_size=7, use_bias=True, name='conv1', padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "        x = AveragePooling2D(4, name='pool1')(x)\n",
    "        \n",
    "        x = QConv2D(filters=3, kernel_size=5, use_bias=True, name='conv2', padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "        x = AveragePooling2D(2, name='pool2')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    x = QDense(36, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense1')(x)\n",
    "    x = QActivation(quantized_relu, name='relu3')(x)\n",
    "\n",
    "    x = QDense(10, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense2')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    name = 'cnn_sparse'\n",
    "    if not is_sparse:\n",
    "        name = 'cnn_full'\n",
    "    return keras.Model(x_in, x, name=name)\n",
    "\n",
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_full.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(cnn_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-3,\n",
    "    patience=15,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "cnn_sparse_t = build_cnn(is_sparse=True, n_max_pixels=8)\n",
    "cnn_sparse_t.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_t.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_s = build_cnn(is_sparse=True, n_max_pixels=12)\n",
    "cnn_sparse_s.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_s.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_m = build_cnn(is_sparse=True, n_max_pixels=16)\n",
    "cnn_sparse_m.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_m.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf30266",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_l = build_cnn(is_sparse=True, n_max_pixels=20)\n",
    "cnn_sparse_l.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_l.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_full.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_full.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e91a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sparse_t_8b = cnn_sparse_t_8b.predict(x_test)\n",
    "y_pred_sparse_s_8b = cnn_sparse_s_8b.predict(x_test)\n",
    "y_pred_sparse_m_8b = cnn_sparse_m_8b.predict(x_test)\n",
    "y_pred_sparse_l_8b = cnn_sparse_l_8b.predict(x_test)\n",
    "y_pred_full_8b = cnn_full_8b.predict(x_test)\n",
    "print(\"acc (sparse cnn-t) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_t_8b, axis=1))))\n",
    "print(\"acc (sparse cnn-s) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_s_8b, axis=1))))\n",
    "print(\"acc (sparse cnn-m) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_m_8b, axis=1))))\n",
    "print(\"acc (sparse cnn-l) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_l_8b, axis=1))))\n",
    "print(\"acc (full cnn) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_full_8b, axis=1))))\n",
    "\n",
    "y_pred_sparse_t_16b = cnn_sparse_t_16b.predict(x_test)\n",
    "y_pred_sparse_s_16b = cnn_sparse_s_16b.predict(x_test)\n",
    "y_pred_sparse_m_16b = cnn_sparse_m_16b.predict(x_test)\n",
    "y_pred_sparse_l_16b = cnn_sparse_l_16b.predict(x_test)\n",
    "y_pred_full_16b = cnn_full_16b.predict(x_test)\n",
    "print(\"acc (sparse cnn-t) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_t_16b, axis=1))))\n",
    "print(\"acc (sparse cnn-s) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_s_16b, axis=1))))\n",
    "print(\"acc (sparse cnn-m) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_m_16b, axis=1))))\n",
    "print(\"acc (sparse cnn-l) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_l_16b, axis=1))))\n",
    "print(\"acc (full cnn) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_full_16b, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, labels):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    for x, label in enumerate(labels):\n",
    "        color = colors[x % len(colors)]\n",
    "        fpr_full, tpr_full, _ = roc_curve(y_test[:, x], y_pred_full[:, x])\n",
    "        fpr_sparse_s, tpr_sparse_s, _ = roc_curve(y_test[:, x], y_pred_sparse_s[:, x])\n",
    "        fpr_sparse_m, tpr_sparse_m, _ = roc_curve(y_test[:, x], y_pred_sparse_m[:, x])\n",
    "        fpr_sparse_l, tpr_sparse_l, _ = roc_curve(y_test[:, x], y_pred_sparse_l[:, x])\n",
    "        plt.plot(tpr_full, fpr_full, label='{0} ({1:.4f}), full'.format(label, auc(fpr_full, tpr_full)), linestyle='-', lw=1.5, color=color)\n",
    "        plt.plot(tpr_sparse_s, fpr_sparse_s, label='{0} ({1:.4f}), sparse-s'.format(label, auc(fpr_sparse_s, tpr_sparse_s)), linestyle='--', lw=1.5, color=color)\n",
    "        plt.plot(tpr_sparse_m, fpr_sparse_m, label='{0} ({1:.4f}), sparse-m'.format(label, auc(fpr_sparse_m, tpr_sparse_m)), linestyle='dotted', lw=1.5, color=color)\n",
    "        plt.plot(tpr_sparse_l, fpr_sparse_l, label='{0} ({1:.4f}), sparse-l'.format(label, auc(fpr_sparse_l, tpr_sparse_l)), linestyle='-.', lw=1.5, color=color)\n",
    "    plt.semilogy()\n",
    "    plt.xlabel(\"tpr\", size=12, loc='right')\n",
    "    plt.ylabel(\"fpr\", size=12, loc='top')\n",
    "    plt.xlim(0., 1)\n",
    "    plt.ylim(0.005, 1)\n",
    "    plt.legend(loc='best', framealpha=0., prop={'size': 6})\n",
    "\n",
    "#plot_roc(y_test, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, ['0','1','2','3','4','5','6','7','8','9'])\n",
    "\n",
    "def plot_auc_vs_label(y_test, y_pred_sparse_t, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, labels):\n",
    "    auc_full = []\n",
    "    auc_sparse_t = []\n",
    "    auc_sparse_s = []\n",
    "    auc_sparse_m = []\n",
    "    auc_sparse_l = []\n",
    "    n_cls = y_test.shape[1]\n",
    "    for k in range(n_cls):\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_full[:, k])\n",
    "        auc_full.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_t[:, k])\n",
    "        auc_sparse_t.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_s[:, k])\n",
    "        auc_sparse_s.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_m[:, k])\n",
    "        auc_sparse_m.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_l[:, k])\n",
    "        auc_sparse_l.append(auc(fpr, tpr))\n",
    "\n",
    "\n",
    "    auc_sparse_t.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_t, axis=1)))\n",
    "    auc_sparse_s.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_s, axis=1)))\n",
    "    auc_sparse_m.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_m, axis=1)))\n",
    "    auc_sparse_l.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_l, axis=1)))\n",
    "    auc_full.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_full, axis=1)))\n",
    "    x = np.arange(n_cls+1)\n",
    "\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    c_full, c_t, c_s, c_m, c_l= colors[:5]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    marker_size = 200\n",
    "    alpha = 0.5\n",
    "    plt.scatter(x, auc_full, s=marker_size, marker=\"o\", color=c_full, label=\"standard\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_t, s=marker_size, marker=\"^\", color=c_t, label=\"sparse-t\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_s, s=marker_size, marker=\"D\", color=c_s, label=\"sparse-s\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_m, s=marker_size, marker=\"s\", color=c_m, label=\"sparse-m\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_l, s=marker_size, marker=\"v\", color=c_l, label=\"sparse-l\", alpha=alpha)\n",
    "\n",
    "    plt.axvline(x=n_cls-0.5, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    plt.xticks(x, labels, fontsize=10)\n",
    "    plt.ylim(0.7, 1.02)\n",
    "    plt.grid(axis=\"y\", alpha=0.2)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_auc_vs_label(y_test, y_pred_sparse_t, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, ['AUC-0','AUC-1','AUC-2','AUC-3','AUC-4','AUC-5','AUC-6','AUC-7','AUC-8','AUC-9','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_auc_vs_label_8b16b(\n",
    "    y_test,\n",
    "    y_pred_sparse_t_8b, y_pred_sparse_s_8b, y_pred_sparse_m_8b, y_pred_sparse_l_8b, y_pred_full_8b,\n",
    "    y_pred_sparse_t_16b, y_pred_sparse_s_16b, y_pred_sparse_m_16b, y_pred_sparse_l_16b, y_pred_full_16b,\n",
    "    labels,\n",
    "    marker_size=200,\n",
    "    filled_alpha=0.6,\n",
    "    hollow_lw=1.8,\n",
    "    dx=0.1,\n",
    "    ylim=(0.7, 1.02),\n",
    "):\n",
    "    def aucs_plus_acc(y_true, y_pred):\n",
    "        n_cls = y_true.shape[1]\n",
    "        vals = []\n",
    "        for k in range(n_cls):\n",
    "            fpr, tpr, _ = roc_curve(y_true[:, k], y_pred[:, k])\n",
    "            vals.append(auc(fpr, tpr))\n",
    "        vals.append(accuracy_score(np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1)))\n",
    "        return np.array(vals)\n",
    "\n",
    "    n_cls = y_test.shape[1]\n",
    "    x = np.arange(n_cls + 1)\n",
    "    x_left, x_right = x - dx, x + dx\n",
    "\n",
    "    vals_16b = {\n",
    "        \"standard\": aucs_plus_acc(y_test, y_pred_full_16b),\n",
    "        \"sparse-t\": aucs_plus_acc(y_test, y_pred_sparse_t_16b),\n",
    "        \"sparse-s\": aucs_plus_acc(y_test, y_pred_sparse_s_16b),\n",
    "        \"sparse-m\": aucs_plus_acc(y_test, y_pred_sparse_m_16b),\n",
    "        \"sparse-l\": aucs_plus_acc(y_test, y_pred_sparse_l_16b),\n",
    "    }\n",
    "    vals_8b = {\n",
    "        \"standard\": aucs_plus_acc(y_test, y_pred_full_8b),\n",
    "        \"sparse-t\": aucs_plus_acc(y_test, y_pred_sparse_t_8b),\n",
    "        \"sparse-s\": aucs_plus_acc(y_test, y_pred_sparse_s_8b),\n",
    "        \"sparse-m\": aucs_plus_acc(y_test, y_pred_sparse_m_8b),\n",
    "        \"sparse-l\": aucs_plus_acc(y_test, y_pred_sparse_l_8b),\n",
    "    }\n",
    "\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    c_full, c_t, c_s, c_m, c_l = colors[:5]\n",
    "    color_map = {\"standard\": c_full, \"sparse-t\": c_t, \"sparse-s\": c_s, \"sparse-m\": c_m, \"sparse-l\": c_l}\n",
    "    marker_map = {\"standard\": \"o\", \"sparse-t\": \"^\", \"sparse-s\": \"D\", \"sparse-m\": \"s\", \"sparse-l\": \"v\"}\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    model_order = [\"standard\", \"sparse-t\", \"sparse-s\", \"sparse-m\", \"sparse-l\"]\n",
    "\n",
    "    handles = []\n",
    "    for name in model_order:\n",
    "        col = color_map[name]; mrk = marker_map[name]\n",
    "        # 16b (right, filled)\n",
    "        h = plt.scatter(x_right, vals_16b[name], s=marker_size, marker=mrk, color=col,\n",
    "                        alpha=filled_alpha, zorder=3, label=name)\n",
    "        handles.append(h)\n",
    "        # 8b (left, hollow)\n",
    "        plt.scatter(x_left, vals_8b[name], s=marker_size, marker=mrk, facecolors=\"none\",\n",
    "                    edgecolors=col, linewidths=hollow_lw, zorder=4)\n",
    "\n",
    "    plt.axvline(x=n_cls - 0.5, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    plt.xticks(x, labels, fontsize=10)\n",
    "    plt.xlim(-0.5 - dx*1.5, n_cls + 0.5 + dx*1.5)\n",
    "    plt.ylim(*ylim)\n",
    "    plt.grid(axis=\"y\", alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    first_legend = plt.legend(handles=handles, loc=\"lower left\", fontsize=12, title=\"Model\")\n",
    "    plt.gca().add_artist(first_legend)\n",
    "    precision_handles = [\n",
    "        Line2D([0], [0], marker='o', linestyle='None', markersize=10,\n",
    "               markerfacecolor='none', markeredgecolor='k', linewidth=0, label='8-bit'),\n",
    "        Line2D([0], [0], marker='o', linestyle='None', markersize=10,\n",
    "               markerfacecolor='k', alpha=filled_alpha, markeredgecolor='k', label='16-bit'),\n",
    "    ]\n",
    "    plt.legend(handles=precision_handles, loc=\"lower right\", fontsize=12, title=\"Precision\")\n",
    "    plt.savefig('plots/mnist_performance.png')\n",
    "\n",
    "plot_auc_vs_label_8b16b(\n",
    "    y_test,\n",
    "    y_pred_sparse_t_8b, y_pred_sparse_s_8b, y_pred_sparse_m_8b, y_pred_sparse_l_8b, y_pred_full_8b,\n",
    "    y_pred_sparse_t_16b, y_pred_sparse_s_16b, y_pred_sparse_m_16b, y_pred_sparse_l_16b, y_pred_full_16b,\n",
    "    ['AUC-0','AUC-1','AUC-2','AUC-3','AUC-4','AUC-5','AUC-6','AUC-7','AUC-8','AUC-9','Accuracy'],\n",
    "    dx=0.16, ylim=(0.6, 1.02)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3896c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [\n",
    "    'x_in', 'input_reduce',\n",
    "    'conv1', 'relu1', 'pool1',\n",
    "    'conv2', 'relu2', 'pool2',\n",
    "]\n",
    "\n",
    "plot_tensors = []\n",
    "plot_names = []\n",
    "for name in layer_names:\n",
    "    layer = cnn_sparse_l_16b.get_layer(name)\n",
    "    output = layer.output\n",
    "    if isinstance(output, (list, tuple)):\n",
    "        plot_tensors.append(output[0])\n",
    "        plot_names.append(f'{name} (x_reduced)')\n",
    "        plot_tensors.append(output[1])\n",
    "        plot_names.append(f'{name} (x_mask)')\n",
    "    else:\n",
    "        plot_tensors.append(output)\n",
    "        plot_names.append(name)\n",
    "\n",
    "model_cnnpart = models.Model(inputs=cnn_sparse_l_16b.input, outputs=plot_tensors)\n",
    "ii=10\n",
    "#ii=21\n",
    "layers_pred = model_cnnpart.predict(x_test[ii:ii+1])\n",
    "print(y_test[ii:ii+1])\n",
    "\n",
    "i = 0\n",
    "cmap='gray'\n",
    "cmap='viridis'\n",
    "while i < len(plot_names):\n",
    "    name = plot_names[i]\n",
    "\n",
    "    if \"(x_reduced)\" in name and i+1 < len(plot_names) and \"(x_mask)\" in plot_names[i+1]:\n",
    "        out_r = layers_pred[i] # (1, h, w, c)\n",
    "        out_m = layers_pred[i+1] # (1, h, w, 1)\n",
    "\n",
    "        arr_r = out_r[0] # (h, w, c)\n",
    "        arr_m = out_m[0,...,0] # (h, w)\n",
    "        h, w, c = arr_r.shape\n",
    "\n",
    "        #fig, axes = plt.subplots(1, c+1, figsize=((c+1)*3, 3))\n",
    "        fig, ax = plt.subplots(1, c, figsize=((c)*3, 3))\n",
    "        #fig.suptitle(name.replace(\" (x_reduced)\", \"\"), fontsize=14)\n",
    "\n",
    "        for ch in range(c):\n",
    "            #ax = axes[ch]\n",
    "            ax.imshow(arr_r[..., ch], cmap=cmap)\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "\n",
    "        #axm = axes[c]\n",
    "        #axm.imshow(arr_m, cmap=cmap)\n",
    "        #axm.set_title(\"mask\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        plt.savefig(f'plots/mnist_conv_in_{i}.png')\n",
    "\n",
    "        i += 2\n",
    "        continue\n",
    "\n",
    "    out = layers_pred[i]\n",
    "    arr = out[0]\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "        #fig.suptitle(name, fontsize=14)\n",
    "        ax.imshow(arr, cmap=cmap)\n",
    "        ax.set_title(\"ch0\")\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        plt.savefig(f'plots/mnist_conv_out_{i}.png')\n",
    "\n",
    "    elif arr.ndim == 3:\n",
    "        h, w, c = arr.shape\n",
    "        fig, axes = plt.subplots(1, c, figsize=(c*3, 3))\n",
    "        #fig.suptitle(name, fontsize=14)\n",
    "        for ch in range(c):\n",
    "            ax = axes[ch] if c>1 else axes\n",
    "            ax.imshow(arr[..., ch], cmap=cmap)\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        plt.savefig(f'plots/mnist_conv_out__{i}.png')\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full.save_weights('weights/mnist_full-16b.h5')\n",
    "cnn_sparse_t.save_weights('weights/mnist_sparse_t-16b.h5')\n",
    "cnn_sparse_s.save_weights('weights/mnist_sparse_s-16b.h5')\n",
    "cnn_sparse_m.save_weights('weights/mnist_sparse_m-16b.h5')\n",
    "cnn_sparse_l.save_weights('weights/mnist_sparse_l-16b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full_8b = build_cnn(is_sparse=False, B=8, I=0)\n",
    "cnn_sparse_t_8b = build_cnn(is_sparse=True, B=8, I=0, n_max_pixels=8)\n",
    "cnn_sparse_s_8b = build_cnn(is_sparse=True, B=8, I=0, n_max_pixels=12)\n",
    "cnn_sparse_m_8b = build_cnn(is_sparse=True, B=8, I=0, n_max_pixels=16)\n",
    "cnn_sparse_l_8b = build_cnn(is_sparse=True, B=8, I=0, n_max_pixels=20)\n",
    "\n",
    "cnn_full_8b.load_weights('weights/mnist_full-8b.h5')\n",
    "cnn_sparse_t_8b.load_weights('weights/mnist_sparse_t-8b.h5')\n",
    "cnn_sparse_s_8b.load_weights('weights/mnist_sparse_s-8b.h5')\n",
    "cnn_sparse_m_8b.load_weights('weights/mnist_sparse_m-8b.h5')\n",
    "cnn_sparse_l_8b.load_weights('weights/mnist_sparse_l-8b.h5')\n",
    "\n",
    "cnn_full_16b = build_cnn(is_sparse=False, B=16, I=6)\n",
    "cnn_sparse_t_16b = build_cnn(is_sparse=True, B=16, I=6, n_max_pixels=8)\n",
    "cnn_sparse_s_16b = build_cnn(is_sparse=True, B=16, I=6, n_max_pixels=12)\n",
    "cnn_sparse_m_16b = build_cnn(is_sparse=True, B=16, I=6, n_max_pixels=16)\n",
    "cnn_sparse_l_16b = build_cnn(is_sparse=True, B=16, I=6, n_max_pixels=20)\n",
    "\n",
    "cnn_full_16b.load_weights('weights/mnist_full-16b.h5')\n",
    "cnn_sparse_t_16b.load_weights('weights/mnist_sparse_t-16b.h5')\n",
    "cnn_sparse_s_16b.load_weights('weights/mnist_sparse_s-16b.h5')\n",
    "cnn_sparse_m_16b.load_weights('weights/mnist_sparse_m-16b.h5')\n",
    "cnn_sparse_l_16b.load_weights('weights/mnist_sparse_l-16b.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a180a",
   "metadata": {},
   "source": [
    "## hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_sparse_forhls(cnn_sparse):\n",
    "    x_in = keras.Input(shape=cnn_sparse.input_shape[1:], name=\"x_in\")\n",
    "    x = x_in\n",
    "    for layer in cnn_sparse.layers:\n",
    "        if isinstance(layer, keras.layers.InputLayer):\n",
    "            continue\n",
    "        if isinstance(layer, InputReduce):\n",
    "            continue\n",
    "        if layer.name.startswith(\"mask_pool\"):\n",
    "            continue\n",
    "\n",
    "        if isinstance(layer, QConv2DSparse):\n",
    "            cfg = layer.conv.get_config()\n",
    "            cfg[\"use_bias\"] = True\n",
    "            cfg[\"name\"] = layer.name\n",
    "            cfg[\"bias_quantizer\"] = layer._bias_quant_cfg\n",
    "\n",
    "            conv_full = QConv2D.from_config(cfg)\n",
    "            x = conv_full(x)\n",
    "\n",
    "            kernel_w = layer.conv.get_weights()[0]\n",
    "            bias_w = keras.backend.get_value(layer.bias)\n",
    "            conv_full.set_weights([kernel_w, bias_w])\n",
    "        elif isinstance(layer, AveragePooling2DSparse):\n",
    "            x = layer.avg_pool(x)\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return keras.Model(x_in, x, name='cnn_sparse_forhls')\n",
    "\n",
    "cnn_sparse_t_forhls = build_cnn_sparse_forhls(cnn_sparse_t)\n",
    "cnn_sparse_s_forhls = build_cnn_sparse_forhls(cnn_sparse_s)\n",
    "cnn_sparse_m_forhls = build_cnn_sparse_forhls(cnn_sparse_m)\n",
    "cnn_sparse_l_forhls = build_cnn_sparse_forhls(cnn_sparse_l)\n",
    "#cnn_sparse_s_forhls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "def write_sparse_hls(cnn_sparse_forhls, name):\n",
    "    config = hls4ml.utils.config_from_keras_model(cnn_sparse_forhls, granularity='name', backend='Vitis')\n",
    "    #config['LayerName']['x_in']['Precision'] = 'ap_ufixed<8,1>'\n",
    "    #config\n",
    "\n",
    "    cnn_sparse_hls = hls4ml.converters.convert_from_keras_model(\n",
    "        cnn_sparse_forhls,\n",
    "        hls_config=config,\n",
    "        project_name='myhls',\n",
    "        backend='Vitis',\n",
    "        output_dir=f'hls_proj/sparsemnist/model-16b/{name}',\n",
    "        part='xcu250-figd2104-2L-e',\n",
    "        io_type='io_parallel',\n",
    "    )\n",
    "\n",
    "    #cnn_sparse_hls.compile()\n",
    "    cnn_sparse_hls.write()\n",
    "\n",
    "write_sparse_hls(cnn_sparse_t_forhls, 'hls_sparse_t')\n",
    "write_sparse_hls(cnn_sparse_s_forhls, 'hls_sparse_s')\n",
    "write_sparse_hls(cnn_sparse_m_forhls, 'hls_sparse_m')\n",
    "write_sparse_hls(cnn_sparse_l_forhls, 'hls_sparse_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(cnn_full, granularity='name', backend='Vivado')\n",
    "#config['LayerName']['x_in']['Precision'] = 'ap_ufixed<8,1>'\n",
    "#config['LayerName']['conv1']['ParallelizationFactor'] = 100\n",
    "#config['LayerName']['conv2']['ParallelizationFactor'] = 50\n",
    "#config\n",
    "\n",
    "cnn_full_hls = hls4ml.converters.convert_from_keras_model(\n",
    "    cnn_full,\n",
    "    hls_config=config,\n",
    "    project_name='myhls',\n",
    "    backend='Vivado',\n",
    "    output_dir='hls_proj/sparsemnist/model-16b/hls_full',\n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    io_type='io_stream',\n",
    ")\n",
    "\n",
    "#cnn_full_hls.compile()\n",
    "cnn_full_hls.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50c5e5",
   "metadata": {},
   "source": [
    "## test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tb = 100\n",
    "x_tb = x_test[:n_tb]\n",
    "y_tb_t = y_pred_sparse_t[:n_tb]\n",
    "y_tb_s = y_pred_sparse_s[:n_tb]\n",
    "y_tb_m = y_pred_sparse_m[:n_tb]\n",
    "y_tb_l = y_pred_sparse_l[:n_tb]\n",
    "y_tb_full = y_pred_full[:n_tb]\n",
    "\n",
    "bit = \"16b\"\n",
    "\n",
    "# inputs\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_t/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_s/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_m/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_l/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_full/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# predictions\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_t/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_t:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_s/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_s:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_m/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_m:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_sparse_l/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_l:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model-\"+bit+\"/hls_full/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_full:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8fdba",
   "metadata": {},
   "source": [
    "## info leak at reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fa762",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sparsemnist(X_train, x_train_pooled, x_train_pooled_inflated, x_train, 4, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e314b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sparsemnist_p(x_original, x_modified1, x_modified2, x_modified3, n_example, threshold, figname=None):\n",
    "    img1 = x_original[n_example+1011]\n",
    "    img2 = x_modified1[n_example+1011]\n",
    "    img3 = x_modified2[n_example+1011]\n",
    "    img4 = x_modified3[n_example+1011]\n",
    "    img5 = np.where(img4 > threshold, img4, 0)\n",
    "\n",
    "    fontsize=18\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "    axes[0].imshow(img1)\n",
    "    #axes[0].set_title('[0] original', fontsize=fontsize)\n",
    "    #axes[1].imshow(img2)\n",
    "    #axes[1].set_title('[1] pooled+padded', fontsize=fontsize)\n",
    "    axes[1].imshow(img3)\n",
    "    #axes[2].set_title('[2] inflated', fontsize=fontsize)\n",
    "    #axes[3].imshow(img4)\n",
    "    #axes[3].set_title('[3] noised', fontsize=fontsize)\n",
    "    #axes[4].imshow(img5)\n",
    "    #axes[4].set_title(f'[4] noised (threshold>{threshold})', fontsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    if figname is not None:\n",
    "     plt.savefig(f'plots/{figname}.png')\n",
    "\n",
    "plot_sparsemnist_p(X_train, x_train_pooled, x_train_pooled_inflated, x_train, 4, threshold=threshold, figname='mnist_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sparsemnist_leak(x_original, x_modified1, x_modified2, x_modified3, n_example, threshold, figname=None):\n",
    "    img1 = x_original[n_example + 1011]\n",
    "    img2 = x_modified1[n_example + 1011]\n",
    "    img3 = x_modified2[n_example + 1011]\n",
    "    img4 = x_modified3[n_example + 1011]\n",
    "    img5 = np.where(img4 > threshold, img4, 0)\n",
    "\n",
    "    img5_2d = img5.squeeze()\n",
    "\n",
    "    def keep_first_k_nonzeros(img2d, k):\n",
    "        flat = img2d.ravel(order='C')\n",
    "        nz_idx = np.flatnonzero(flat)\n",
    "        k = min(k, nz_idx.size)\n",
    "        if k == 0:\n",
    "            return np.zeros_like(img2d)\n",
    "        keep = np.zeros_like(flat, dtype=bool)\n",
    "        keep[nz_idx[:k]] = True\n",
    "        keep = keep.reshape(img2d.shape)\n",
    "        return np.where(keep, img2d, 0)\n",
    "\n",
    "    imgs = [\n",
    "        #img5_2d,\n",
    "        keep_first_k_nonzeros(img5_2d, 4),\n",
    "        keep_first_k_nonzeros(img5_2d, 8),\n",
    "        keep_first_k_nonzeros(img5_2d, 12),\n",
    "        keep_first_k_nonzeros(img5_2d, 16),\n",
    "    ]\n",
    "\n",
    "    fontsize = 18\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    vmax = float(img5_2d.max()) if img5_2d.max() > 0 else 1.0\n",
    "\n",
    "    for ax, im in zip(axes, imgs):\n",
    "        ax.imshow(im, vmin=0, vmax=vmax)\n",
    "        #ax.set_title(title, fontsize=fontsize)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if figname is not None:\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        plt.savefig(f\"plots/{figname}.png\")\n",
    "\n",
    "plot_sparsemnist_leak(X_train, x_train_pooled, x_train_pooled_inflated, x_train, 4, threshold=threshold, figname='mnist_leak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9908e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8096a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5685ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
