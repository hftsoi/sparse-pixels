{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d15a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import models, Model\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "from sparsepixels.layers import *\n",
    "from sparsepixels.utils import *\n",
    "import h5py\n",
    "import glob\n",
    "import os\n",
    "\n",
    "with h5py.File(\"datasets/jet/train.h5\", \"r\") as f:\n",
    "    x = f[\"x\"][:450000]\n",
    "    y = f[\"y\"][:450000]\n",
    "\n",
    "threshold = 0\n",
    "plot_jetimage(x, y, n_examples=3, threshold=threshold)\n",
    "\n",
    "x = x.reshape(-1, 50, 2, 50, 2, 1).sum(axis=(2, 4))[:, 15:35, 15:35, :]\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#plot_jetimage(x, y, n_examples=3, threshold=threshold)\n",
    "\n",
    "x = x / 1000\n",
    "x = np.where(x>1, 1, x)\n",
    "\n",
    "#plot_jetimage(x, y, n_examples=3, threshold=threshold, normalized=True)\n",
    "\n",
    "threshold = 0.004\n",
    "x = np.where(x>threshold, x, 0)\n",
    "\n",
    "plot_jetimage(x, y, n_examples=3, threshold=threshold, normalized=True)\n",
    "\n",
    "n_train = 300000\n",
    "n_val = 50000\n",
    "n_test = 100000\n",
    "\n",
    "x_train = x[:n_train]\n",
    "y_train = y[:n_train]\n",
    "x_val = x[n_train:n_train+n_val]\n",
    "y_val = y[n_train:n_train+n_val]\n",
    "x_test = x[n_train+n_val:n_train+n_val+n_test]\n",
    "y_test = y[n_train+n_val:n_train+n_val+n_test]\n",
    "\n",
    "print(\"x_train.shape: \" + str(x_train.shape))\n",
    "print(\"y_train.shape: \" + str(y_train.shape))\n",
    "print(\"x_val.shape: \" + str(x_val.shape))\n",
    "print(\"y_val.shape: \" + str(y_val.shape))\n",
    "print(\"x_test.shape: \" + str(x_test.shape))\n",
    "print(\"y_test.shape: \" + str(y_test.shape))\n",
    "\n",
    "import os\n",
    "import random\n",
    "os.environ['PYTHONHASHSEED'] = str(1219)\n",
    "random.seed(1219)\n",
    "tf.random.set_seed(1219)\n",
    "np.random.seed(1219)\n",
    "del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(is_sparse, n_max_pixels=None):\n",
    "    quantizer = quantized_bits(8, 0, alpha=1)\n",
    "    quantized_relu = 'quantized_relu(8, 0)'\n",
    "\n",
    "    x_in = keras.Input(shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3]), name='x_in')\n",
    "    if is_sparse:\n",
    "        x, keep_mask = InputReduce(n_max_pixels=n_max_pixels, threshold=0, name='input_reduce')(x_in)\n",
    "    else:\n",
    "        x = x_in\n",
    "\n",
    "    if is_sparse:\n",
    "        x = QConv2DSparse(filters=3, kernel_size=(3, 3), use_bias=True, name='conv1',\n",
    "                          padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "        x, keep_mask = AveragePooling2DSparse(2, name='pool1')([x, keep_mask])\n",
    "\n",
    "        x = QConv2DSparse(filters=1, kernel_size=(3, 3), use_bias=True, name='conv2',\n",
    "                          padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "\n",
    "    else:\n",
    "        x = QConv2D(filters=3, kernel_size=(3, 3), use_bias=True, name='conv1',\n",
    "                    padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "        x = AveragePooling2D(2, name='pool1')(x)\n",
    "\n",
    "        x = QConv2D(filters=1, kernel_size=(3, 3), use_bias=True, name='conv2',\n",
    "                    padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    x = QDense(64, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense1')(x)\n",
    "    x = QActivation(quantized_relu, name='relu3')(x)\n",
    "\n",
    "    x = QDense(5, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense2')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    name = 'cnn_sparse'\n",
    "    if not is_sparse:\n",
    "        name = 'cnn_full'\n",
    "    return keras.Model(x_in, x, name=name)\n",
    "\n",
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_full.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(cnn_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0dff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-3,\n",
    "    patience=15,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "cnn_sparse_t = build_cnn(is_sparse=True, n_max_pixels=8)\n",
    "cnn_sparse_t.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_t.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3bb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_s = build_cnn(is_sparse=True, n_max_pixels=12)\n",
    "cnn_sparse_s.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_s.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bde8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_m = build_cnn(is_sparse=True, n_max_pixels=16)\n",
    "cnn_sparse_m.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_m.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sparse_l = build_cnn(is_sparse=True, n_max_pixels=20)\n",
    "cnn_sparse_l.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_sparse_l.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_full.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = cnn_full.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sparse_t = cnn_sparse_t.predict(x_test)\n",
    "y_pred_sparse_s = cnn_sparse_s.predict(x_test)\n",
    "y_pred_sparse_m = cnn_sparse_m.predict(x_test)\n",
    "y_pred_sparse_l = cnn_sparse_l.predict(x_test)\n",
    "y_pred_full = cnn_full.predict(x_test)\n",
    "print(\"acc (sparse cnn-t) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_t, axis=1))))\n",
    "print(\"acc (sparse cnn-s) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_s, axis=1))))\n",
    "print(\"acc (sparse cnn-m) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_m, axis=1))))\n",
    "print(\"acc (sparse cnn-l) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_l, axis=1))))\n",
    "print(\"acc (full cnn) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_full, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86177491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred_sparse_t, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, labels):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    for x, label in enumerate(labels):\n",
    "        color = colors[x % len(colors)]\n",
    "        fpr_full, tpr_full, _ = roc_curve(y_test[:, x], y_pred_full[:, x])\n",
    "        #fpr_sparse_t, tpr_sparse_t, _ = roc_curve(y_test[:, x], y_pred_sparse_t[:, x])\n",
    "        #fpr_sparse_s, tpr_sparse_s, _ = roc_curve(y_test[:, x], y_pred_sparse_s[:, x])\n",
    "        #fpr_sparse_m, tpr_sparse_m, _ = roc_curve(y_test[:, x], y_pred_sparse_m[:, x])\n",
    "        fpr_sparse_l, tpr_sparse_l, _ = roc_curve(y_test[:, x], y_pred_sparse_l[:, x])\n",
    "        plt.plot(tpr_full, fpr_full, label='{0} ({1:.4f}), full'.format(label, auc(fpr_full, tpr_full)), linestyle='-', lw=1.5, color=color)\n",
    "        #plt.plot(tpr_sparse_t, fpr_sparse_t, label='{0} ({1:.4f}), sparse-t'.format(label, auc(fpr_sparse_t, tpr_sparse_t)), linestyle='--', lw=1.5, color=color)\n",
    "        #plt.plot(tpr_sparse_s, fpr_sparse_s, label='{0} ({1:.4f}), sparse-s'.format(label, auc(fpr_sparse_s, tpr_sparse_s)), linestyle='--', lw=1.5, color=color)\n",
    "        #plt.plot(tpr_sparse_m, fpr_sparse_m, label='{0} ({1:.4f}), sparse-m'.format(label, auc(fpr_sparse_m, tpr_sparse_m)), linestyle='dotted', lw=1.5, color=color)\n",
    "        plt.plot(tpr_sparse_l, fpr_sparse_l, label='{0} ({1:.4f}), sparse-l'.format(label, auc(fpr_sparse_l, tpr_sparse_l)), linestyle='--', lw=1.5, color=color)\n",
    "    plt.semilogy()\n",
    "    plt.xlabel(\"tpr\", size=12, loc='right')\n",
    "    plt.ylabel(\"fpr\", size=12, loc='top')\n",
    "    plt.xlim(0., 1)\n",
    "    plt.ylim(0.0001, 1)\n",
    "    plt.legend(loc='best', framealpha=0., prop={'size': 10})\n",
    "\n",
    "#plot_roc(y_test, y_pred_sparse_t, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, ['g','q','W','Z','t'])\n",
    "\n",
    "def plot_auc_vs_label(y_test, y_pred_sparse_t, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, labels):\n",
    "    auc_full = []\n",
    "    auc_sparse_t = []\n",
    "    auc_sparse_s = []\n",
    "    auc_sparse_m = []\n",
    "    auc_sparse_l = []\n",
    "    n_cls = y_test.shape[1]\n",
    "    for k in range(n_cls):\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_full[:, k])\n",
    "        auc_full.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_t[:, k])\n",
    "        auc_sparse_t.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_s[:, k])\n",
    "        auc_sparse_s.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_m[:, k])\n",
    "        auc_sparse_m.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_l[:, k])\n",
    "        auc_sparse_l.append(auc(fpr, tpr))\n",
    "\n",
    "\n",
    "    auc_sparse_t.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_t, axis=1)))\n",
    "    auc_sparse_s.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_s, axis=1)))\n",
    "    auc_sparse_m.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_m, axis=1)))\n",
    "    auc_sparse_l.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_l, axis=1)))\n",
    "    auc_full.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_full, axis=1)))\n",
    "    x = np.arange(n_cls+1)\n",
    "\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    c_full, c_t, c_s, c_m, c_l = colors[:5]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    marker_size = 200\n",
    "    alpha = 0.5\n",
    "    plt.scatter(x, auc_full, s=marker_size, marker=\"o\", color=c_full, label=\"full\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_t, s=marker_size, marker=\"^\", color=c_t, label=\"sparse-t\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_s, s=marker_size, marker=\"D\", color=c_s, label=\"sparse-s\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_m, s=marker_size, marker=\"s\", color=c_m, label=\"sparse-m\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_l, s=marker_size, marker=\"v\", color=c_l, label=\"sparse-l\", alpha=alpha)\n",
    "\n",
    "    plt.axvline(x=n_cls-0.5, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    plt.xticks(x, labels, fontsize=10)\n",
    "    plt.ylim(0.5, 1.02)\n",
    "    plt.grid(axis=\"y\", alpha=0.2)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_auc_vs_label(y_test, y_pred_sparse_t, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, ['AUC-g','AUC-q','AUC-W','AUC-Z','AUC-t','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf74e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [\n",
    "    'x_in', 'input_reduce',\n",
    "    'conv1', 'relu1', 'pool1',\n",
    "    'conv2', 'relu2', #'pool1',\n",
    "]\n",
    "\n",
    "plot_tensors = []\n",
    "plot_names = []\n",
    "for name in layer_names:\n",
    "    layer = cnn_sparse_l.get_layer(name)\n",
    "    output = layer.output\n",
    "    if isinstance(output, (list, tuple)):\n",
    "        plot_tensors.append(output[0])\n",
    "        plot_names.append(f'{name} (x_reduced)')\n",
    "        plot_tensors.append(output[1])\n",
    "        plot_names.append(f'{name} (x_mask)')\n",
    "    else:\n",
    "        plot_tensors.append(output)\n",
    "        plot_names.append(name)\n",
    "\n",
    "model_cnnpart = models.Model(inputs=cnn_sparse_l.input, outputs=plot_tensors)\n",
    "layers_pred = model_cnnpart.predict(x_test[1:2])\n",
    "\n",
    "i = 0\n",
    "while i < len(plot_names):\n",
    "    name = plot_names[i]\n",
    "\n",
    "    if \"(x_reduced)\" in name and i+1 < len(plot_names) and \"(x_mask)\" in plot_names[i+1]:\n",
    "        out_r = layers_pred[i] # (1, h, w, c)\n",
    "        out_m = layers_pred[i+1] # (1, h, w, 1)\n",
    "\n",
    "        arr_r = out_r[0] # (h, w, c)\n",
    "        arr_m = out_m[0,...,0] # (h, w)\n",
    "        h, w, c = arr_r.shape\n",
    "\n",
    "        fig, axes = plt.subplots(1, c+1, figsize=((c+1)*3, 3))\n",
    "        fig.suptitle(name.replace(\" (x_reduced)\", \"\"), fontsize=14)\n",
    "\n",
    "        for ch in range(c):\n",
    "            ax = axes[ch]\n",
    "            ax.imshow(arr_r[..., ch], cmap='gray')\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "\n",
    "        axm = axes[c]\n",
    "        axm.imshow(arr_m, cmap='gray')\n",
    "        axm.set_title(\"mask\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        i += 2\n",
    "        continue\n",
    "\n",
    "    out = layers_pred[i]\n",
    "    arr = out[0]\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "        fig.suptitle(name, fontsize=14)\n",
    "        ax.imshow(arr, cmap='gray')\n",
    "        ax.set_title(\"ch0\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    elif arr.ndim == 3:\n",
    "        h, w, c = arr.shape\n",
    "        fig, axes = plt.subplots(1, c, figsize=(c*3, 3))\n",
    "        fig.suptitle(name, fontsize=14)\n",
    "        for ch in range(c):\n",
    "            ax = axes[ch] if c>1 else axes\n",
    "            ax.imshow(arr[..., ch], cmap='gray')\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c89d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full.save_weights('weights/jet_full-8b.h5')\n",
    "cnn_sparse_t.save_weights('weights/jet_sparse_t-8b.h5')\n",
    "cnn_sparse_s.save_weights('weights/jet_sparse_s-8b.h5')\n",
    "cnn_sparse_m.save_weights('weights/jet_sparse_m-8b.h5')\n",
    "cnn_sparse_l.save_weights('weights/jet_sparse_l-8b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87478a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_sparse_t = build_cnn(is_sparse=True, n_max_pixels=8)\n",
    "cnn_sparse_s = build_cnn(is_sparse=True, n_max_pixels=12)\n",
    "cnn_sparse_m = build_cnn(is_sparse=True, n_max_pixels=16)\n",
    "cnn_sparse_l = build_cnn(is_sparse=True, n_max_pixels=20)\n",
    "\n",
    "cnn_full.load_weights('weights/jet_full-8b.h5')\n",
    "cnn_sparse_t.load_weights('weights/jet_sparse_t-8b.h5')\n",
    "cnn_sparse_s.load_weights('weights/jet_sparse_s-8b.h5')\n",
    "cnn_sparse_m.load_weights('weights/jet_sparse_m-8b.h5')\n",
    "cnn_sparse_l.load_weights('weights/jet_sparse_l-8b.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4a21d",
   "metadata": {},
   "source": [
    "## hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60139423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_sparse_forhls(cnn_sparse):\n",
    "    x_in = keras.Input(shape=cnn_sparse.input_shape[1:], name=\"x_in\")\n",
    "    x = x_in\n",
    "    for layer in cnn_sparse.layers:\n",
    "        if isinstance(layer, keras.layers.InputLayer):\n",
    "            continue\n",
    "        if isinstance(layer, InputReduce):\n",
    "            continue\n",
    "        if layer.name.startswith(\"mask_pool\"):\n",
    "            continue\n",
    "\n",
    "        if isinstance(layer, QConv2DSparse):\n",
    "            cfg = layer.conv.get_config()\n",
    "            cfg[\"use_bias\"] = True\n",
    "            cfg[\"name\"] = layer.name\n",
    "            cfg[\"bias_quantizer\"] = layer._bias_quant_cfg\n",
    "\n",
    "            conv_full = QConv2D.from_config(cfg)\n",
    "            x = conv_full(x)\n",
    "\n",
    "            kernel_w = layer.conv.get_weights()[0]\n",
    "            bias_w = keras.backend.get_value(layer.bias)\n",
    "            conv_full.set_weights([kernel_w, bias_w])\n",
    "        elif isinstance(layer, AveragePooling2DSparse):\n",
    "            x = layer.avg_pool(x)\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return keras.Model(x_in, x, name='cnn_sparse_forhls')\n",
    "\n",
    "cnn_sparse_t_forhls = build_cnn_sparse_forhls(cnn_sparse_t)\n",
    "cnn_sparse_s_forhls = build_cnn_sparse_forhls(cnn_sparse_s)\n",
    "cnn_sparse_m_forhls = build_cnn_sparse_forhls(cnn_sparse_m)\n",
    "cnn_sparse_l_forhls = build_cnn_sparse_forhls(cnn_sparse_l)\n",
    "cnn_sparse_s_forhls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "def write_sparse_hls(cnn_sparse_forhls, name):\n",
    "    config = hls4ml.utils.config_from_keras_model(cnn_sparse_forhls, granularity='name', backend='Vitis')\n",
    "    config['LayerName']['x_in']['Precision'] = 'ap_ufixed<8,1>'\n",
    "    #config\n",
    "\n",
    "    cnn_sparse_hls = hls4ml.converters.convert_from_keras_model(\n",
    "        cnn_sparse_forhls,\n",
    "        hls_config=config,\n",
    "        project_name='myhls',\n",
    "        backend='Vitis',\n",
    "        output_dir=f'hls_proj/jet/model-8b/{name}',\n",
    "        part='xcu250-figd2104-2L-e',\n",
    "        #io_type='io_stream',\n",
    "        io_type='io_parallel',\n",
    "    )\n",
    "\n",
    "    #cnn_sparse_hls.compile()\n",
    "    cnn_sparse_hls.write()\n",
    "\n",
    "write_sparse_hls(cnn_sparse_t_forhls, 'hls_sparse_t')\n",
    "write_sparse_hls(cnn_sparse_s_forhls, 'hls_sparse_s')\n",
    "write_sparse_hls(cnn_sparse_m_forhls, 'hls_sparse_m')\n",
    "write_sparse_hls(cnn_sparse_l_forhls, 'hls_sparse_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(cnn_full, granularity='name', backend='Vitis')\n",
    "config['LayerName']['x_in']['Precision'] = 'ap_ufixed<8,1>'\n",
    "config['LayerName']['conv1']['ParallelizationFactor'] = 200\n",
    "config['LayerName']['conv2']['ParallelizationFactor'] = 50\n",
    "#config\n",
    "\n",
    "cnn_full_hls = hls4ml.converters.convert_from_keras_model(\n",
    "    cnn_full,\n",
    "    hls_config=config,\n",
    "    project_name='myhls',\n",
    "    backend='Vitis',\n",
    "    output_dir='hls_proj/jet/model-8b/hls_full',\n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    #io_type='io_stream',\n",
    "    io_type='io_parallel',\n",
    ")\n",
    "\n",
    "#cnn_full_hls.compile()\n",
    "cnn_full_hls.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93634ae2",
   "metadata": {},
   "source": [
    "## test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bc8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tb = 100\n",
    "x_tb = x_test[:n_tb]\n",
    "y_tb_t = y_pred_sparse_t[:n_tb]\n",
    "y_tb_s = y_pred_sparse_s[:n_tb]\n",
    "y_tb_m = y_pred_sparse_m[:n_tb]\n",
    "y_tb_l = y_pred_sparse_l[:n_tb]\n",
    "y_tb_full = y_pred_full[:n_tb]\n",
    "\n",
    "bit = \"8b\"\n",
    "\n",
    "# inputs\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_t/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_s/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_m/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_l/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_full/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# predictions\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_t/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_t:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_s/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_s:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_m/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_m:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_sparse_l/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_l:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/jet/model-\"+bit+\"/hls_full/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_full:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43cd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
