{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import models, Model\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "from sparsepixels.layers import *\n",
    "from sparsepixels.utils import *\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "n_val = 10000\n",
    "X_val = X_train[:n_val]\n",
    "y_val = y_train[:n_val]\n",
    "X_train = X_train[n_val:]\n",
    "y_train = y_train[n_val:]\n",
    "\n",
    "X_train = np.reshape(X_train, (-1,28,28,1)) / 255.\n",
    "X_val = np.reshape(X_val, (-1,28,28,1)) / 255.\n",
    "X_test = np.reshape(X_test, (-1,28,28,1)) / 255.\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"y_train.shape: \" + str(y_train.shape))\n",
    "print(\"X_val.shape: \" + str(X_val.shape))\n",
    "print(\"y_val.shape: \" + str(y_val.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"y_test.shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c655197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "os.environ['PYTHONHASHSEED'] = str(1221)\n",
    "random.seed(1221)\n",
    "tf.random.set_seed(1221)\n",
    "np.random.seed(121)\n",
    "\n",
    "noise_type='uniform'\n",
    "#noise_type='poisson'\n",
    "#noise_level=0.42\n",
    "noise_level=0\n",
    "inflate_factor=3.5\n",
    "threshold=0.4\n",
    "target_size_x=40\n",
    "target_size_y=target_size_x\n",
    "\n",
    "x_train_pooled = pool_pad_noise_inflate(X_train, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=0, inflate_factor=1)\n",
    "x_train_pooled_inflated = pool_pad_noise_inflate(X_train, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=0, inflate_factor=inflate_factor)\n",
    "\n",
    "x_train = pool_pad_noise_inflate(X_train, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=noise_level, inflate_factor=inflate_factor)\n",
    "x_val = pool_pad_noise_inflate(X_val, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=noise_level, inflate_factor=inflate_factor)\n",
    "x_test = pool_pad_noise_inflate(X_test, pool_size=3, pool_type='avg', target_size=(target_size_x,target_size_y), noise_type=noise_type, noise_level=noise_level, inflate_factor=inflate_factor)\n",
    "\n",
    "x_train[x_train < threshold] = 0.\n",
    "x_val[x_val < threshold] = 0.\n",
    "x_test[x_test < threshold] = 0.\n",
    "\n",
    "for i in range(9):\n",
    "    plot_sparsemnist(X_train, x_train_pooled, x_train_pooled_inflated, x_train, i, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(is_sparse, n_max_pixels=None):\n",
    "    quantizer = quantized_bits(6, 0, alpha=1)\n",
    "    quantized_relu = 'quantized_relu(6, 0)'\n",
    "\n",
    "    x_in = keras.Input(shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3]), name='x_in')\n",
    "    if is_sparse:\n",
    "        x, keep_mask = InputReduce(n_max_pixels=n_max_pixels, threshold=threshold, name='input_reduce')(x_in)\n",
    "    else:\n",
    "        x = x_in\n",
    "\n",
    "    if is_sparse:\n",
    "        x = QConv2DSparse(filters=2, kernel_size=(3, 3), use_bias=True, name='conv1',\n",
    "                          padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "        x, keep_mask = AveragePooling2DSparse(4, name='pool1')([x, keep_mask])\n",
    "\n",
    "        x = QConv2DSparse(filters=2, kernel_size=(3, 3), use_bias=True, name='conv2',\n",
    "                          padding='same', strides=1,\n",
    "                          kernel_quantizer=quantizer, bias_quantizer=quantizer)([x, keep_mask])\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "        x, keep_mask = AveragePooling2DSparse(2, name='pool2')([x, keep_mask])\n",
    "\n",
    "    else:\n",
    "        x = QConv2D(filters=2, kernel_size=(3, 3), use_bias=True, name='conv1',\n",
    "                    padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu1')(x)\n",
    "        x = AveragePooling2D(4, name='pool1')(x)\n",
    "        \n",
    "        x = QConv2D(filters=2, kernel_size=(3, 3), use_bias=True, name='conv2',\n",
    "                    padding='same', strides=1,\n",
    "                    kernel_quantizer=quantizer, bias_quantizer=quantizer)(x)\n",
    "        x = QActivation(quantized_relu, name='relu2')(x)\n",
    "        x = AveragePooling2D(2, name='pool2')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    x = QDense(64, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense1')(x)\n",
    "    x = QActivation(quantized_relu, name='relu3')(x)\n",
    "\n",
    "    x = QDense(10, kernel_quantizer=quantizer, bias_quantizer=quantizer, name='dense2')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    name = 'cnn_sparse'\n",
    "    if not is_sparse:\n",
    "        name = 'cnn_full'\n",
    "    return keras.Model(x_in, x, name=name)\n",
    "\n",
    "cnn_sparse_s = build_cnn(is_sparse=True, n_max_pixels=10)\n",
    "cnn_sparse_s.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "cnn_sparse_m = build_cnn(is_sparse=True, n_max_pixels=15)\n",
    "cnn_sparse_m.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "cnn_sparse_l = build_cnn(is_sparse=True, n_max_pixels=20)\n",
    "cnn_sparse_l.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "cnn_sparse_h = build_cnn(is_sparse=True, n_max_pixels=25)\n",
    "cnn_sparse_h.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_full.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(cnn_sparse_s.summary())\n",
    "print(cnn_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-3,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "history = cnn_sparse_s.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_sparse_m.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_sparse_l.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf30266",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_sparse_h.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_full.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=128, callbacks=[early_stop])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label='train loss')\n",
    "axes.plot(history.history['val_loss'], label='val loss')\n",
    "axes.legend(loc=\"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e91a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sparse_s = cnn_sparse_s.predict(x_test)\n",
    "y_pred_sparse_m = cnn_sparse_m.predict(x_test)\n",
    "y_pred_sparse_l = cnn_sparse_l.predict(x_test)\n",
    "y_pred_sparse_h = cnn_sparse_h.predict(x_test)\n",
    "y_pred_full = cnn_full.predict(x_test)\n",
    "print(\"acc (sparse cnn-s) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_s, axis=1))))\n",
    "print(\"acc (sparse cnn-m) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_m, axis=1))))\n",
    "print(\"acc (sparse cnn-l) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_l, axis=1))))\n",
    "print(\"acc (sparse cnn-h) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_h, axis=1))))\n",
    "print(\"acc (full cnn) = {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_full, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, labels):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    for x, label in enumerate(labels):\n",
    "        color = colors[x % len(colors)]\n",
    "        fpr_full, tpr_full, _ = roc_curve(y_test[:, x], y_pred_full[:, x])\n",
    "        fpr_sparse_s, tpr_sparse_s, _ = roc_curve(y_test[:, x], y_pred_sparse_s[:, x])\n",
    "        fpr_sparse_m, tpr_sparse_m, _ = roc_curve(y_test[:, x], y_pred_sparse_m[:, x])\n",
    "        fpr_sparse_l, tpr_sparse_l, _ = roc_curve(y_test[:, x], y_pred_sparse_l[:, x])\n",
    "        plt.plot(tpr_full, fpr_full, label='{0} ({1:.4f}), full'.format(label, auc(fpr_full, tpr_full)), linestyle='-', lw=1.5, color=color)\n",
    "        plt.plot(tpr_sparse_s, fpr_sparse_s, label='{0} ({1:.4f}), sparse-s'.format(label, auc(fpr_sparse_s, tpr_sparse_s)), linestyle='--', lw=1.5, color=color)\n",
    "        plt.plot(tpr_sparse_m, fpr_sparse_m, label='{0} ({1:.4f}), sparse-m'.format(label, auc(fpr_sparse_m, tpr_sparse_m)), linestyle='dotted', lw=1.5, color=color)\n",
    "        plt.plot(tpr_sparse_l, fpr_sparse_l, label='{0} ({1:.4f}), sparse-l'.format(label, auc(fpr_sparse_l, tpr_sparse_l)), linestyle='-.', lw=1.5, color=color)\n",
    "    plt.semilogy()\n",
    "    plt.xlabel(\"tpr\", size=12, loc='right')\n",
    "    plt.ylabel(\"fpr\", size=12, loc='top')\n",
    "    plt.xlim(0., 1)\n",
    "    plt.ylim(0.005, 1)\n",
    "    plt.legend(loc='best', framealpha=0., prop={'size': 6})\n",
    "\n",
    "#plot_roc(y_test, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_full, ['0','1','2','3','4','5','6','7','8','9'])\n",
    "\n",
    "def plot_auc_vs_label(y_test, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_sparse_h, y_pred_full, labels):\n",
    "    auc_full = []\n",
    "    auc_sparse_s = []\n",
    "    auc_sparse_m = []\n",
    "    auc_sparse_l = []\n",
    "    auc_sparse_h = []\n",
    "    n_cls = y_test.shape[1]\n",
    "    for k in range(n_cls):\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_full[:, k])\n",
    "        auc_full.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_s[:, k])\n",
    "        auc_sparse_s.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_m[:, k])\n",
    "        auc_sparse_m.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_l[:, k])\n",
    "        auc_sparse_l.append(auc(fpr, tpr))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, k], y_pred_sparse_h[:, k])\n",
    "        auc_sparse_h.append(auc(fpr, tpr))\n",
    "\n",
    "    auc_sparse_s.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_s, axis=1)))\n",
    "    auc_sparse_m.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_m, axis=1)))\n",
    "    auc_sparse_l.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_l, axis=1)))\n",
    "    auc_sparse_h.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_sparse_h, axis=1)))\n",
    "    auc_full.append(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_full, axis=1)))\n",
    "    x = np.arange(n_cls+1)\n",
    "\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    c_full, c_s, c_m, c_l, c_h = colors[:5]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    marker_size = 200\n",
    "    alpha = 0.5\n",
    "    plt.scatter(x, auc_full, s=marker_size, marker=\"o\", color=c_full, label=\"full\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_s, s=marker_size, marker=\"^\", color=c_s, label=\"sparse-s\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_m, s=marker_size, marker=\"D\", color=c_m, label=\"sparse-m\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_l, s=marker_size, marker=\"s\", color=c_l, label=\"sparse-l\", alpha=alpha)\n",
    "    plt.scatter(x, auc_sparse_h, s=marker_size, marker=\"v\", color=c_h, label=\"sparse-h\", alpha=alpha)\n",
    "\n",
    "    plt.axvline(x=n_cls-0.5, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    plt.xticks(x, labels, fontsize=10)\n",
    "    plt.ylim(0.75, 1.02)\n",
    "    plt.grid(axis=\"y\", alpha=0.2)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_auc_vs_label(y_test, y_pred_sparse_s, y_pred_sparse_m, y_pred_sparse_l, y_pred_sparse_h, y_pred_full, ['AUC-0','AUC-1','AUC-2','AUC-3','AUC-4','AUC-5','AUC-6','AUC-7','AUC-8','AUC-9','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3896c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [\n",
    "    'x_in', 'input_reduce',\n",
    "    'conv1', 'relu1', 'pool1',\n",
    "    'conv2', 'relu2', 'pool2',\n",
    "]\n",
    "\n",
    "plot_tensors = []\n",
    "plot_names = []\n",
    "for name in layer_names:\n",
    "    layer = cnn_sparse_m.get_layer(name)\n",
    "    output = layer.output\n",
    "    if isinstance(output, (list, tuple)):\n",
    "        plot_tensors.append(output[0])\n",
    "        plot_names.append(f'{name} (x_reduced)')\n",
    "        plot_tensors.append(output[1])\n",
    "        plot_names.append(f'{name} (x_mask)')\n",
    "    else:\n",
    "        plot_tensors.append(output)\n",
    "        plot_names.append(name)\n",
    "\n",
    "model_cnnpart = models.Model(inputs=cnn_sparse_m.input, outputs=plot_tensors)\n",
    "layers_pred = model_cnnpart.predict(x_test[1:2])\n",
    "\n",
    "i = 0\n",
    "while i < len(plot_names):\n",
    "    name = plot_names[i]\n",
    "\n",
    "    if \"(x_reduced)\" in name and i+1 < len(plot_names) and \"(x_mask)\" in plot_names[i+1]:\n",
    "        out_r = layers_pred[i] # (1, h, w, c)\n",
    "        out_m = layers_pred[i+1] # (1, h, w, 1)\n",
    "\n",
    "        arr_r = out_r[0] # (h, w, c)\n",
    "        arr_m = out_m[0,...,0] # (h, w)\n",
    "        h, w, c = arr_r.shape\n",
    "\n",
    "        fig, axes = plt.subplots(1, c+1, figsize=((c+1)*3, 3))\n",
    "        fig.suptitle(name.replace(\" (x_reduced)\", \"\"), fontsize=14)\n",
    "\n",
    "        for ch in range(c):\n",
    "            ax = axes[ch]\n",
    "            ax.imshow(arr_r[..., ch], cmap='gray')\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "\n",
    "        axm = axes[c]\n",
    "        axm.imshow(arr_m, cmap='gray')\n",
    "        axm.set_title(\"mask\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        i += 2\n",
    "        continue\n",
    "\n",
    "    out = layers_pred[i]\n",
    "    arr = out[0]\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "        fig.suptitle(name, fontsize=14)\n",
    "        ax.imshow(arr, cmap='gray')\n",
    "        ax.set_title(\"ch0\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    elif arr.ndim == 3:\n",
    "        h, w, c = arr.shape\n",
    "        fig, axes = plt.subplots(1, c, figsize=(c*3, 3))\n",
    "        fig.suptitle(name, fontsize=14)\n",
    "        for ch in range(c):\n",
    "            ax = axes[ch] if c>1 else axes\n",
    "            ax.imshow(arr[..., ch], cmap='gray')\n",
    "            ax.set_title(f\"ch{ch}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full.save_weights('weights/mnist_full.h5')\n",
    "cnn_sparse_s.save_weights('weights/mnist_sparse_s.h5')\n",
    "cnn_sparse_m.save_weights('weights/mnist_sparse_m.h5')\n",
    "cnn_sparse_l.save_weights('weights/mnist_sparse_l.h5')\n",
    "cnn_sparse_h.save_weights('weights/mnist_sparse_h.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_full = build_cnn(is_sparse=False)\n",
    "cnn_sparse_s = build_cnn(is_sparse=True, n_max_pixels=10)\n",
    "cnn_sparse_m = build_cnn(is_sparse=True, n_max_pixels=15)\n",
    "cnn_sparse_l = build_cnn(is_sparse=True, n_max_pixels=20)\n",
    "cnn_sparse_h = build_cnn(is_sparse=True, n_max_pixels=25)\n",
    "\n",
    "cnn_full.load_weights('weights/mnist_full.h5')\n",
    "cnn_sparse_s.load_weights('weights/mnist_sparse_s.h5')\n",
    "cnn_sparse_m.load_weights('weights/mnist_sparse_m.h5')\n",
    "cnn_sparse_l.load_weights('weights/mnist_sparse_l.h5')\n",
    "cnn_sparse_h.load_weights('weights/mnist_sparse_h.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a180a",
   "metadata": {},
   "source": [
    "## hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_sparse_forhls(cnn_sparse):\n",
    "    x_in = keras.Input(shape=cnn_sparse.input_shape[1:], name=\"x_in\")\n",
    "    x = x_in\n",
    "    for layer in cnn_sparse.layers:\n",
    "        if isinstance(layer, keras.layers.InputLayer):\n",
    "            continue\n",
    "        if isinstance(layer, InputReduce):\n",
    "            continue\n",
    "        if layer.name.startswith(\"mask_pool\"):\n",
    "            continue\n",
    "\n",
    "        if isinstance(layer, QConv2DSparse):\n",
    "            cfg = layer.conv.get_config()\n",
    "            cfg[\"use_bias\"] = True\n",
    "            cfg[\"name\"] = layer.name\n",
    "            cfg[\"bias_quantizer\"] = layer._bias_quant_cfg\n",
    "\n",
    "            conv_full = QConv2D.from_config(cfg)\n",
    "            x = conv_full(x)\n",
    "\n",
    "            kernel_w = layer.conv.get_weights()[0]\n",
    "            bias_w = keras.backend.get_value(layer.bias)\n",
    "            conv_full.set_weights([kernel_w, bias_w])\n",
    "        elif isinstance(layer, AveragePooling2DSparse):\n",
    "            x = layer.avg_pool(x)\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return keras.Model(x_in, x, name='cnn_sparse_forhls')\n",
    "\n",
    "cnn_sparse_s_forhls = build_cnn_sparse_forhls(cnn_sparse_s)\n",
    "cnn_sparse_m_forhls = build_cnn_sparse_forhls(cnn_sparse_m)\n",
    "cnn_sparse_l_forhls = build_cnn_sparse_forhls(cnn_sparse_l)\n",
    "cnn_sparse_h_forhls = build_cnn_sparse_forhls(cnn_sparse_h)\n",
    "cnn_sparse_s_forhls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "def write_sparse_hls(cnn_sparse_forhls, name):\n",
    "    config = hls4ml.utils.config_from_keras_model(cnn_sparse_forhls, granularity='name', backend='Vitis')\n",
    "    #config\n",
    "\n",
    "    cnn_sparse_hls = hls4ml.converters.convert_from_keras_model(\n",
    "        cnn_sparse_forhls,\n",
    "        hls_config=config,\n",
    "        project_name='hls_sparse',\n",
    "        backend='Vitis',\n",
    "        output_dir=f'hls_proj/sparsemnist/model/{name}',\n",
    "        part='xcu250-figd2104-2L-e',\n",
    "        #io_type='io_stream',\n",
    "        io_type='io_parallel',\n",
    "    )\n",
    "\n",
    "    #cnn_sparse_hls.compile()\n",
    "    cnn_sparse_hls.write()\n",
    "\n",
    "write_sparse_hls(cnn_sparse_s_forhls, 'hls_sparse_s')\n",
    "write_sparse_hls(cnn_sparse_m_forhls, 'hls_sparse_m')\n",
    "write_sparse_hls(cnn_sparse_l_forhls, 'hls_sparse_l')\n",
    "write_sparse_hls(cnn_sparse_h_forhls, 'hls_sparse_h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(cnn_full, granularity='name', backend='Vitis')\n",
    "config['LayerName']['conv1']['ParallelizationFactor'] = 800\n",
    "config['LayerName']['conv2']['ParallelizationFactor'] = 50\n",
    "config\n",
    "\n",
    "cnn_full_hls = hls4ml.converters.convert_from_keras_model(\n",
    "    cnn_full,\n",
    "    hls_config=config,\n",
    "    project_name='hls_full',\n",
    "    backend='Vitis',\n",
    "    output_dir='hls_proj/sparsemnist/model/hls_full',\n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    #io_type='io_stream',\n",
    "    io_type='io_parallel',\n",
    ")\n",
    "\n",
    "#cnn_full_hls.compile()\n",
    "cnn_full_hls.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50c5e5",
   "metadata": {},
   "source": [
    "## test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tb = 40\n",
    "x_tb = x_test[:n_tb]\n",
    "y_tb_s = y_pred_sparse_s[:n_tb]\n",
    "y_tb_m = y_pred_sparse_m[:n_tb]\n",
    "y_tb_l = y_pred_sparse_l[:n_tb]\n",
    "y_tb_h = y_pred_sparse_h[:n_tb]\n",
    "y_tb_full = y_pred_full[:n_tb]\n",
    "\n",
    "# inputs\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_s/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_m/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_l/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_h/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_full/tb_data/tb_input_features.dat\", \"w\") as f:\n",
    "    x_tb_flat = x_tb.reshape(n_tb, -1)\n",
    "    for row in x_tb_flat:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# predictions\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_s/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_s:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_m/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_m:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_l/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_l:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_sparse_h/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_h:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"hls_proj/sparsemnist/model/hls_full/tb_data/tb_output_predictions.dat\", \"w\") as f:\n",
    "    for row in y_tb_full:\n",
    "        f.write(\" \".join(str(v) for v in row))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fa762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
